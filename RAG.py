import os
from PyPDF2 import PdfReader
import re
import streamlit as st
import logging
import weaviate
import openai
from dotenv import load_dotenv

# 1. .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

# 2. í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
openai.api_key = os.getenv("OPENAI_API_KEY")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Weaviate í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
WEAVIATE_URL = "http://localhost:8080"
client = weaviate.Client(WEAVIATE_URL)

# Weaviateì— ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìƒì„±
def create_weaviate_schema():
    try:
        existing_classes = [cls['class'] for cls in client.schema.get()["classes"]]
        if "Document" in existing_classes:
            logger.info("Document í´ë˜ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        schema = {
            "classes": [
                {
                    "class": "Document",
                    "description": "A document from PDF files",
                    "properties": [
                        {"name": "filename", "dataType": ["string"], "description": "The name of the PDF file"},
                        {"name": "content", "dataType": ["text"], "description": "The original content of the PDF"},
                        {"name": "processed_content", "dataType": ["text"], "description": "The processed content of the PDF"}
                    ]
                }
            ]
        }
        client.schema.create(schema)
    except Exception as e:
        logger.error(f"Weaviate ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        st.error("Weaviate ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdfs(pdf_folder):
    texts = []
    filenames = []
    for filename in os.listdir(pdf_folder):
        if filename.lower().endswith('.pdf'):
            filepath = os.path.join(pdf_folder, filename)
            try:
                reader = PdfReader(filepath)
                text = ''
                for page_num, page in enumerate(reader.pages, start=1):
                    extracted_text = page.extract_text()
                    if extracted_text:
                        text += extracted_text
                    else:
                        logger.warning(f"í˜ì´ì§€ {page_num}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
                texts.append(text)
                filenames.append(filename)
                logger.info(f"ì„±ê³µì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤: {filename}")
            except Exception as e:
                logger.error(f"{filename} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    return filenames, texts

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def preprocess_text(text):
    try:
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

# í…ìŠ¤íŠ¸ ë¶„ë¥˜ í•¨ìˆ˜
def classify_product(text):
    try:
        # í‚¤ì›Œë“œì™€ ê°€ì¤‘ì¹˜ ì„¤ì •
        keywords = {
            'ì±„ê¶Œ': {
                'words': [
                    'ì±„ê¶Œ', 'êµ­ì±„', 'íšŒì‚¬ì±„', 'ì‹ ìš©ë“±ê¸‰', 'ë°œí–‰ì', 'ê±°ì¹˜ ê¸°ê°„', 'ìœ ë™ì„±',
                    'í‘œë©´ ì´ìœ¨', 'ë°œí–‰ê¸°ê´€', 'ë°œí–‰ê¸ˆì•¡', 'ìˆ˜ìµë¥ ', 'ë°œí–‰ì¼', 'í• ì¸ ì±„ê¶Œ',
                    'ì±„ê¶Œ ì‹œì¥', 'íˆ¬ì ë“±ê¸‰', 'ê¸°ê°„ ì±„ê¶Œ', 'ë§Œê¸° ì±„ê¶Œ', 'êµ­ë‚´ ì±„ê¶Œ',
                    'í•´ì™¸ ì±„ê¶Œ', 'ì±„ê¶Œ í€ë“œ', 'ì¥ê¸° ì±„ê¶Œ', 'ë‹¨ê¸° ì±„ê¶Œ', 'ì±„ê¶Œ ë“±ê¸‰'
                ],
                'weight': 5
            },
            'ì ê¸ˆ': {
                'words': ['ì ê¸ˆ', 'ì €ì¶•', 'ì›” ì ë¦½', 'ìë™ ì´ì²´', 'ì •ê¸°', 'ë‚©ì…', 'ì¶œê¸ˆ ì œí•œ'],
                'weight': 5
            },
            'ì˜ˆê¸ˆ': {
                'words': ['ì˜ˆê¸ˆ', 'ì •ê¸°ì˜ˆê¸ˆ', 'ê±°ì¹˜', 'ì´ì', 'íŒŒí‚¹ í†µì¥', 'ë‹¨ë¦¬', 'ë³µë¦¬', 'ê³ ì • ê¸ˆë¦¬', 'ë³€ë™ ê¸ˆë¦¬'],
                'weight': 5
            },
            'ì²­ë…„': {
                'words': ['ì²­ë…„', 'ì²­ë…„ë‚´ì¼ì €ì¶•ê³„ì¢Œ', 'ì²­ë…„ë„ì•½ê³„ì¢Œ', 'ì²­ë…„í¬ë§ì ê¸ˆ'],
                'weight': 8
            }
        }

        # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì´ˆê¸°í™”
        category_scores = {category: 0 for category in keywords}

        # ê° ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œì— ëŒ€í•´ í…ìŠ¤íŠ¸ ë‚´ ë“±ì¥ ì—¬ë¶€ í™•ì¸
        for category, data in keywords.items():
            for word in data['words']:
                if re.search(r'\b' + re.escape(word) + r'\b', text, re.IGNORECASE):
                    category_scores[category] += data['weight']

        # ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ì •ë ¬
        sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)
        top_category, top_score = sorted_categories[0]

        # ì ìˆ˜ê°€ 0ë³´ë‹¤ í° ê²½ìš° í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë°˜í™˜, ì•„ë‹ˆë©´ 'ë¯¸ì§€ì •' ë°˜í™˜
        return top_category if top_score > 0 else 'ë¯¸ì§€ì •'
    except Exception as e:
        logger.error(f"ìƒí’ˆ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ë¯¸ì§€ì •"


# ì†Œë“ë¶„ìœ„ ê³„ì‚° í•¨ìˆ˜
def calculate_income_level(asset_size, monthly_salary):
    try:
        if asset_size <= 5000000:
            asset_level = 1
        elif asset_size <= 10000000:
            asset_level = 2
        elif asset_size <= 20000000:
            asset_level = 3
        elif asset_size <= 30000000:
            asset_level = 4
        elif asset_size <= 50000000:
            asset_level = 5
        elif asset_size <= 70000000:
            asset_level = 6
        elif asset_size <= 100000000:
            asset_level = 7
        elif asset_size <= 200000000:
            asset_level = 8
        elif asset_size <= 500000000:
            asset_level = 9
        else:
            asset_level = 10

        if monthly_salary <= 1500000:
            salary_level = 1
        elif monthly_salary <= 2000000:
            salary_level = 2
        elif monthly_salary <= 2500000:
            salary_level = 3
        elif monthly_salary <= 3000000:
            salary_level = 4
        elif monthly_salary <= 3500000:
            salary_level = 5
        elif monthly_salary <= 4000000:
            salary_level = 6
        elif monthly_salary <= 4500000:
            salary_level = 7
        elif monthly_salary <= 5000000:
            salary_level = 8
        elif monthly_salary <= 7000000:
            salary_level = 9
        else:
            salary_level = 10

        average_level = (asset_level + salary_level) / 2
        return round(average_level)
    except Exception as e:
        logger.error(f"ì†Œë“ë¶„ìœ„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0

# MBTI ê¸°ë°˜ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œ
def classify_product_with_mbti(income_level, wants_loan, age, mbti):
    try:
        # I vs E: ì•ˆì •ì„± vs. ê³ ìˆ˜ìµ
        if 'I' in mbti:
            risk_preference = "ì•ˆì •ì„±"
        else:
            risk_preference = "ê³ ìˆ˜ìµ"

        # J vs P: ì¥ê¸°ì„± vs. ë‹¨ê¸°ì„±
        if 'J' in mbti:
            term_preference = "ì¥ê¸°ì„±"
        else:
            term_preference = "ë‹¨ê¸°ì„±"

        if wants_loan:
            return "ì±„ê¶Œ"

        if risk_preference == "ì•ˆì •ì„±":
            if income_level < 6:
                return "ì ê¸ˆ"
            else:
                return "ì˜ˆê¸ˆ"
        else:  # ê³ ìˆ˜ìµ ì„ í˜¸
            if age <= 34 and term_preference == "ì¥ê¸°ì„±":
                return "ì²­ë…„"
            else:
                return "ì±„ê¶Œ"
    except Exception as e:
        logger.error(f"MBTI ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ë¯¸ì§€ì •"

# Weaviateì— ë°ì´í„° ì €ì¥
def save_to_weaviate(filename, content, processed_content):
    try:
        # ì¤‘ë³µ ì²´í¬: ë™ì¼í•œ íŒŒì¼ëª…ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        response = client.query.get("Document", ["filename"]).with_where({
            "path": ["filename"],
            "operator": "Equal",
            "valueText": filename
        }).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        if documents:
            logger.info(f"{filename} íŒŒì¼ì´ ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¤‘ë³µ ì €ì¥ì„ ë°©ì§€í•©ë‹ˆë‹¤.")
            return

        # ì¤‘ë³µì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ì €ì¥
        data_object = {
            "filename": filename,
            "content": content,
            "processed_content": processed_content
        }
        client.data_object.create(data_object, "Document")
        logger.info(f"{filename} íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ Weaviateì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Weaviateì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        st.error(f"{filename} íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")




# Weaviateì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
def get_documents_by_category(category):
    try:
        response = client.query.get("Document", ["filename", "keywords"]).with_where({
            "path": ["category"],
            "operator": "Equal",
            "valueText": category
        }).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        return documents
    except Exception as e:
        logger.error(f"Weaviateì—ì„œ {category} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# Weaviateì—ì„œ RAG ì¿¼ë¦¬ ìˆ˜í–‰
def perform_rag_query(query):
    try:
        response = client.query.get("Document", ["content", "keywords", "category"]).with_near_text({
            "concepts": [query],
            "certainty": 0.5  # í™•ì‹¤ì„± ê°’ì„ ì¡°ì •í•´ ë” ë§ì€ ê²°ê³¼ ë°˜í™˜
        }).with_limit(5).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        return documents
    except Exception as e:
        logger.error(f"RAG ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def number_to_korean(num):
    units = ["", "ë§Œ", "ì–µ", "ì¡°", "ê²½"]
    num_str = str(int(num))
    length = len(num_str)
    korean_num = ""

    for idx, digit in enumerate(num_str):
        if digit != "0":
            korean_num += digit + units[(length - idx - 1) // 4]

    return f"{int(num):,}ì› ({korean_num})"

# MBTI ê¸°ë°˜ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œ í•¨ìˆ˜
# MBTI ê¸°ë°˜ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œ í•¨ìˆ˜
def classify_product_with_mbti(income_level, wants_loan, age, mbti):
    try:
        # I vs E: ì•ˆì •ì„± vs. ê³ ìˆ˜ìµ
        if 'I' in mbti:
            risk_preference = "ì•ˆì •ì„±"
        else:
            risk_preference = "ê³ ìˆ˜ìµ"

        # J vs P: ì¥ê¸°ì„± vs. ë‹¨ê¸°ì„±
        if 'J' in mbti:
            term_preference = "ì¥ê¸°ì„±"
        else:
            term_preference = "ë‹¨ê¸°ì„±"

        # N vs S: ë¯¸ë˜ ìˆ˜ìµ ë³€ë™ì„± vs. í˜„ì¬ ê³ ì • ì´ììœ¨
        if 'N' in mbti:
            return_type_preference = "ë¯¸ë˜ ìˆ˜ìµ ë³€ë™ì„±"
        else:
            return_type_preference = "í˜„ì¬ ê³ ì • ì´ììœ¨"

        # ìƒí’ˆ ì¶”ì²œ ë¡œì§
        if wants_loan:
            return "ì±„ê¶Œ"

        if risk_preference == "ì•ˆì •ì„±":
            if income_level < 6:
                return "ì ê¸ˆ" if return_type_preference == "í˜„ì¬ ê³ ì • ì´ììœ¨" else "ì˜ˆê¸ˆ"
            else:
                return "ì˜ˆê¸ˆ" if return_type_preference == "í˜„ì¬ ê³ ì • ì´ììœ¨" else "ì±„ê¶Œ"
        else:  # ê³ ìˆ˜ìµ ì„ í˜¸
            if age <= 34 and term_preference == "ì¥ê¸°ì„±":
                return "ì²­ë…„" if return_type_preference == "ë¯¸ë˜ ìˆ˜ìµ ë³€ë™ì„±" else "ì±„ê¶Œ"
            else:
                return "ì±„ê¶Œ" if return_type_preference == "ë¯¸ë˜ ìˆ˜ìµ ë³€ë™ì„±" else "ì˜ˆê¸ˆ"
    except Exception as e:
        logger.error(f"MBTI ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ë¯¸ì§€ì •"

def fetch_all_documents():
    try:
        response = client.query.get("Document", ["filename", "content", "processed_content", "category", "income_level"]).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        return documents
    except Exception as e:
        logger.error(f"Weaviateì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def perform_rag_based_analysis_and_mapping(user_query, mbti=None):
    try:
        # Weaviateì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        documents = perform_rag_query(user_query)
        if not documents:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë¬¸ì„œ ë‚´ìš©ì„ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ë¶„ì„í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        context = "\n\n".join([doc['content'] for doc in documents])
        analysis_prompt = f"""
        ë„ˆëŠ” ê¸ˆìœµ ë° ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ë‹¤ìŒì€ ê´€ë ¨ëœ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤:

        {context}

        1. ê° ë¬¸ì„œì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.
        2. ë¬¸ì„œë¥¼ ì„œë¡œ ìœ ì‚¬ì„±ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ë§í•´ì¤˜.
        3. ì£¼ì–´ì§„ MBTI ìœ í˜•({mbti})ì— ë”°ë¼ ì ì ˆí•œ ê¸ˆìœµ ìƒí’ˆì„ ë§¤í•‘í•´ì¤˜.
        """

        # LLMì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
            messages=[
                {"role": "user", "content": analysis_prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        answer = completion.choices[0].message['content'].strip()
        return answer
    except Exception as e:
        logger.error(f"RAG ê¸°ë°˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "RAG ê¸°ë°˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def check_weaviate_data():
    try:
        response = client.query.get("Document", ["filename"]).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        if not documents:
            logger.error("Weaviateì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        else:
            logger.info(f"Weaviateì— {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤.")
            return True
    except Exception as e:
        logger.error(f"Weaviate ë°ì´í„° ì ê²€ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

import nltk
from nltk.tokenize import sent_tokenize
nltk.download('punkt')

# Weaviateì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
# ë¬¸ì„œ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
def summarize_text(text, max_sentences=2):
    try:
        sentences = sent_tokenize(text)
        if len(sentences) > max_sentences:
            return " ".join(sentences[:max_sentences])
        return text
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return text


# Weaviateì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
def fetch_all_documents():
    try:
        response = client.query.get("Document", ["filename", "content"]).do()
        documents = response.get("data", {}).get("Get", {}).get("Document", [])
        return documents
    except Exception as e:
        logger.error(f"Weaviateì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# LLM ê¸°ë°˜ ë¶„ì„ ë° ì§ˆë¬¸ ì²˜ë¦¬
def handle_user_query(user_query):
    try:
        # Weaviateì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        documents = fetch_all_documents()
        if not documents:
            return "Weaviateì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë¬¸ì„œ ìˆ˜ë¥¼ ì œí•œí•˜ê³  ë‚´ìš©ì„ ìš”ì•½
        max_documents = 100000000 # í•„ìš”í•œ ê²½ìš° ì¡°ì •
        context = "\n\n".join([
            summarize_text(doc['content'], max_sentences=1)  # í•œ ë¬¸ì¥ë§Œ ìš”ì•½
            for doc in documents[:max_documents]
        ])

        # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ë‹¤ìŒì€ ì¼ë¶€ ë¬¸ì„œì˜ ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤:
        {context}

        ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_query}
        ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ì ì ˆíˆ ë‹µë³€í•´ ì£¼ì„¸ìš”.
        """

        # LLM í˜¸ì¶œ
        completion = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AIì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4096,  # í•„ìš”í•œ ê²½ìš°, max_tokens ê°’ì„ ë” ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            temperature=0.7
        )
        answer = completion.choices[0].message['content'].strip()
        return answer
    except Exception as e:
        logger.error(f"LLM ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "LLM ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."



def perform_grouping_and_mapping(user_query):
    try:
        # Weaviateì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        documents = fetch_all_documents()
        if not documents:
            return "Weaviateì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë¬¸ì„œ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "\n\n".join([summarize_text(doc['content'], max_sentences=2) for doc in documents[:10]])

        # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ë‹¤ìŒì€ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
        {context}

        ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_query}
        ë¬¸ì„œë¥¼ ì ì ˆíˆ ë¶„ì„í•˜ê³  ê·¸ë£¹í™”í•œ í›„, ê¸ˆìœµ ìƒí’ˆì„ ë§¤í•‘í•´ ì£¼ì„¸ìš”.
        """

        # LLM í˜¸ì¶œ
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê¸ˆìœµ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        answer = completion.choices[0].message['content'].strip()
        return answer
    except Exception as e:
        logger.error(f"LLM ê¸°ë°˜ ê·¸ë£¹í™” ë° ë§¤í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "LLM ê¸°ë°˜ ê·¸ë£¹í™” ë° ë§¤í•‘ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def main():
    st.title("ğŸ“„ PDF ë‚´ìš© ì¶”ì¶œ ë° Weaviate ì €ì¥ ì‹œìŠ¤í…œ")

    # 1. PDF íŒŒì¼ ì¶”ì¶œ ë° Weaviateì— ì €ì¥
    st.header("1ï¸âƒ£ PDF ë‚´ìš© ì¶”ì¶œ ë° DB ì €ì¥")
    pdf_folder = st.text_input("ğŸ“ PDF íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”", "/Users/im-woojin/Desktop/ì‹ í•œì€í–‰/ì‹ í•œì€í–‰_ë°ì´í„°")

    if st.button("ğŸ” PDF ë‚´ìš© ì¶”ì¶œ ë° DB ì €ì¥"):
        if not os.path.exists(pdf_folder):
            st.error("ì…ë ¥í•œ í´ë” ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return

        create_weaviate_schema()

        with st.spinner("ğŸ“„ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
            filenames, documents = extract_text_from_pdfs(pdf_folder)
            if not filenames:
                st.warning("í•´ë‹¹ í´ë”ì— PDF íŒŒì¼ì´ ì—†ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            processed_documents = [preprocess_text(doc) for doc in documents]

            for filename, content, proc_content in zip(filenames, documents, processed_documents):
                save_to_weaviate(filename, content, proc_content)  # category ì¸ìˆ˜ ì œê±°

        st.success("ğŸš€ ëª¨ë“  ë¬¸ì„œê°€ Weaviateì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # 2. DB ì‹œê°í™”
    st.header("2ï¸âƒ£ DB ì‹œê°í™”")
    if st.button("ğŸ“Š ëª¨ë“  ë¬¸ì„œ ë³´ê¸°"):
        documents = fetch_all_documents()
        if documents:
            st.write("DBì— ì €ì¥ëœ ë¬¸ì„œë“¤:")
            for doc in documents:
                st.write(f"**íŒŒì¼ëª…**: {doc['filename']}")
                st.write(f"**ë‚´ìš© ìš”ì•½**: {doc['content'][:200]}...")  # ë‚´ìš©ì˜ ì¼ë¶€ë§Œ ì¶œë ¥
                st.write("---")
        else:
            st.warning("DBì— ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 3. LLM ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œ
    st.header("3ï¸âƒ£ LLM ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œ")
    user_query = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

    if st.button("ğŸ’¡ ì§ˆë¬¸ ì²˜ë¦¬"):
        with st.spinner("LLMì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            answer = handle_user_query(user_query)
            st.subheader("ğŸ¤– LLMì˜ ì‘ë‹µ")
            st.write(answer)

    # 4. ì‚¬ìš©ì ì •ë³´ ì…ë ¥ ë° MBTI ê¸°ë°˜ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œ
    st.header("4ï¸âƒ£ ì‚¬ìš©ì ì •ë³´ ì…ë ¥ ë° MBTI ê¸°ë°˜ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œ")
    # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì‚¬ìš©
    with st.container():
        with st.form("user_input_form"):
            asset_size = st.number_input("ğŸ’° ìì‚° ê·œëª¨ (ì›)", min_value=0, format="%d", value=0)
            monthly_salary = st.number_input("ğŸ’µ ì›”ê¸‰ (ì›)", min_value=0, format="%d", value=0)
            age = st.number_input("ğŸ‚ ë‚˜ì´ (ë§Œ ë‚˜ì´)", min_value=0, value=0)
            wants_loan = st.checkbox("ğŸ“‹ ì±„ê¶Œì„ í¬ë§í•˜ì‹­ë‹ˆê¹Œ?", value=False)
            mbti = st.text_input("ğŸ§  MBTI ìœ í˜•ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: INTJ, ENFP)", value="")

            # ìì‚° ê·œëª¨ì™€ ì›”ê¸‰ì„ í•œê¸€ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
            st.write(f"ì…ë ¥í•œ ìì‚° ê·œëª¨: {number_to_korean(asset_size)}")
            st.write(f"ì…ë ¥í•œ ì›”ê¸‰: {number_to_korean(monthly_salary)}")

            # ì œì¶œ ë²„íŠ¼ ì¶”ê°€
            submit_button = st.form_submit_button("ğŸ¯ ì œí’ˆ ì¶”ì²œ")

        if submit_button:
            income_level = calculate_income_level(asset_size, monthly_salary)
            recommendation = classify_product_with_mbti(income_level, wants_loan, age, mbti)
            st.write(f"ì†Œë“ë¶„ìœ„: {income_level}, ì¶”ì²œ ìƒí’ˆ: {recommendation}")

if __name__ == "__main__":
    main()
